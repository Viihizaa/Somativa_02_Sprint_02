{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(RANDOM_SEED)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas\n",
    "modelos = []\n",
    "acuracia = []\n",
    "precisao = []\n",
    "sensibilidade = []\n",
    "especificidade = []\n",
    "f1_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers():\n",
    "  for i in range(0, len(acuracia)):\n",
    "    print(\"modelo: \" + str(modelos[i]) + \" possui acuracia de \" + str(acuracia[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas de classificação\n",
    "def metricas( list_pred, modelo):\n",
    "  for i in range(0,len(list_pred)):\n",
    "    cm = confusion_matrix(y_test, list_pred[i])\n",
    "\n",
    "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "    prec = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "    sens = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    esp=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    f1 = 2*prec*sens/(precisao+sensibilidade)\n",
    "\n",
    "    modelos.append(modelo[i]), acuracia.append(acc), precisao.append(prec), sensibilidade.append(sens), especificidade.append(esp), f1_score.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitbih_train = pd.read_csv('mitbih_train.csv', header=None)\n",
    "mitbih_test = pd.read_csv('mitbih_test.csv', header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Variáveis para treino\n",
    "X_train = mitbih_train.iloc[:, :-1].values\n",
    "y_train = mitbih_train.iloc[:, -1].values\n",
    "\n",
    "# Variáveis para teste e validação (50% teste - 50% validação)\n",
    "X_test, X_val, y_test, y_val = train_test_split(mitbih_test.iloc[:, :-1].values,\n",
    "                                                mitbih_test.iloc[:, -1].values,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=RANDOM_SEED)\n",
    "\n",
    "#X_test = mitbih_test.iloc[:, :-1].values\n",
    "#y_test = mitbih_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [5]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [2]\n",
      "\n",
      "model  0:     [SVC]\n",
      "    fold  0:  [0.96430815]\n",
      "    fold  1:  [0.96881960]\n",
      "    fold  2:  [0.96733482]\n",
      "    fold  3:  [0.96687796]\n",
      "    fold  4:  [0.96938892]\n",
      "    ----\n",
      "    MEAN:     [0.96734589] + [0.00177723]\n",
      "    FULL:     [0.96734587]\n",
      "\n",
      "model  1:     [AdaBoostClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.85928845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.85803209]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.84723888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.87145223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  4:  [0.87567105]\n",
      "    ----\n",
      "    MEAN:     [0.86233654] + [0.01016527]\n",
      "    FULL:     [0.86233639]\n",
      "\n",
      "modelo: stacking possui acuracia de 0.9850408953938872\n"
     ]
    }
   ],
   "source": [
    "# initializing all the base model objects with default parameters\n",
    "model_1 = SVC(random_state=42)\n",
    "model_2 = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# putting all base model objects in one list\n",
    "all_models = [model_1, model_2]\n",
    "\n",
    "# computing the stack features\n",
    "s_train, s_test = stacking(all_models, X_train, y_train,  X_test, regression=False, n_folds=5, shuffle=True, verbose=2)\n",
    "\n",
    "# initializing the second-level model\n",
    "#model_stacking = LogisticRegression()\n",
    "model_stacking = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# fitting the second level model with stack features\n",
    "model_stacking = model_stacking.fit(s_train, y_train)\n",
    "\n",
    "# predicting the final output using stacking\n",
    "ypred_stacking = model_stacking.predict(s_test)\n",
    "\n",
    "\n",
    "list_pred = [ypred_stacking]\n",
    "modelo = ['stacking']\n",
    "metricas(list_pred, modelo)\n",
    "get_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação - Validação (Stacking)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      9106\n",
      "         1.0       0.98      0.60      0.74       267\n",
      "         2.0       0.96      0.86      0.91       694\n",
      "         3.0       0.69      0.42      0.52        84\n",
      "         4.0       0.99      0.91      0.95       795\n",
      "\n",
      "    accuracy                           0.97     10946\n",
      "   macro avg       0.92      0.76      0.82     10946\n",
      "weighted avg       0.97      0.97      0.97     10946\n",
      "\n",
      "Relatório de Classificação - Teste (Stacking)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      9012\n",
      "         1.0       0.96      0.53      0.68       289\n",
      "         2.0       0.98      0.86      0.91       754\n",
      "         3.0       0.80      0.56      0.66        78\n",
      "         4.0       1.00      0.90      0.95       813\n",
      "\n",
      "    accuracy                           0.97     10946\n",
      "   macro avg       0.94      0.77      0.84     10946\n",
      "weighted avg       0.97      0.97      0.96     10946\n",
      "\n",
      "Especificidade Média do Stacking (Teste): 0.9646\n",
      "Especificidade Média do Stacking (Validação): 0.9675\n"
     ]
    }
   ],
   "source": [
    "for model in all_models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "s_val = np.column_stack([model.predict(X_val) for model in all_models])\n",
    "\n",
    "y_val_pred = model_stacking.predict(s_val)\n",
    "classification_report_val = classification_report(y_val, y_val_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "y_test_pred = model_stacking.predict(s_test)\n",
    "classification_report_test = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "print(\"Relatório de Classificação - Validação (Stacking)\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "\n",
    "print(\"Relatório de Classificação - Teste (Stacking)\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "specificities_test = []\n",
    "for i in range(len(cm_test)):\n",
    "    TN = np.sum(cm_test) - np.sum(cm_test[i, :]) - np.sum(cm_test[:, i]) + cm_test[i, i]\n",
    "    FP = np.sum(cm_test[:, i]) - cm_test[i, i]\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    specificities_test.append(specificity)\n",
    "\n",
    "specificity_mean_test = np.mean(specificities_test)\n",
    "print(f\"Especificidade Média do Stacking (Teste): {specificity_mean_test:.4f}\")\n",
    "\n",
    "specificities_val = []\n",
    "for i in range(len(cm_val)):\n",
    "    TN = np.sum(cm_val) - np.sum(cm_val[i, :]) - np.sum(cm_val[:, i]) + cm_val[i, i]\n",
    "    FP = np.sum(cm_val[:, i]) - cm_val[i, i]\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    specificities_val.append(specificity)\n",
    "\n",
    "specificity_mean_val = np.mean(specificities_val)\n",
    "print(f\"Especificidade Média do Stacking (Validação): {specificity_mean_val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

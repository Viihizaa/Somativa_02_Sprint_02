{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(RANDOM_SEED)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas\n",
    "modelos = []\n",
    "acuracia = []\n",
    "precisao = []\n",
    "sensibilidade = []\n",
    "especificidade = []\n",
    "f1_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers():\n",
    "  for i in range(0, len(acuracia)):\n",
    "    print(\"modelo: \" + str(modelos[i]) + \" possui acuracia de \" + str(acuracia[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas de classificação\n",
    "def metricas( list_pred, modelo):\n",
    "  for i in range(0,len(list_pred)):\n",
    "    cm = confusion_matrix(y_test, list_pred[i])\n",
    "\n",
    "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "    prec = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "    sens = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    esp=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    f1 = 2*prec*sens/(precisao+sensibilidade)\n",
    "\n",
    "    modelos.append(modelo[i]), acuracia.append(acc), precisao.append(prec), sensibilidade.append(sens), especificidade.append(esp), f1_score.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitbih_train = pd.read_csv('mitbih_train.csv', header=None)\n",
    "mitbih_test = pd.read_csv('mitbih_test.csv', header=None)\n",
    "\n",
    "\n",
    "\n",
    "# Variáveis para treino\n",
    "X_train = mitbih_train.iloc[:, :-1].values\n",
    "y_train = mitbih_train.iloc[:, -1].values\n",
    "\n",
    "# Variáveis para teste e validação (50% teste - 50% validação)\n",
    "X_test, X_val, y_test, y_val = train_test_split(mitbih_test.iloc[:, :-1].values,\n",
    "                                                mitbih_test.iloc[:, -1].values,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=RANDOM_SEED)\n",
    "\n",
    "#X_test = mitbih_test.iloc[:, :-1].values\n",
    "#y_test = mitbih_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [5]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [6]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.97236023]\n",
      "    fold  1:  [0.97618640]\n",
      "    fold  2:  [0.97493004]\n",
      "    fold  3:  [0.97595797]\n",
      "    fold  4:  [0.97595660]\n",
      "    ----\n",
      "    MEAN:     [0.97507825] + [0.00142709]\n",
      "    FULL:     [0.97507824]\n",
      "\n",
      "model  1:     [GradientBoostingClassifier]\n",
      "    fold  0:  [0.96225230]\n",
      "    fold  1:  [0.96447947]\n",
      "    fold  2:  [0.96470790]\n",
      "    fold  3:  [0.96293758]\n",
      "    fold  4:  [0.96527698]\n",
      "    ----\n",
      "    MEAN:     [0.96393085] + [0.00114201]\n",
      "    FULL:     [0.96393083]\n",
      "\n",
      "model  2:     [SVC]\n",
      "    fold  0:  [0.96430815]\n",
      "    fold  1:  [0.96881960]\n",
      "    fold  2:  [0.96733482]\n",
      "    fold  3:  [0.96687796]\n",
      "    fold  4:  [0.96938892]\n",
      "    ----\n",
      "    MEAN:     [0.96734589] + [0.00177723]\n",
      "    FULL:     [0.96734587]\n",
      "\n",
      "model  3:     [MLPClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.97344526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.97590086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.97698589]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.97675747]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  4:  [0.97669903]\n",
      "    ----\n",
      "    MEAN:     [0.97595770] + [0.00130858]\n",
      "    FULL:     [0.97595769]\n",
      "\n",
      "model  4:     [KNeighborsClassifier]\n",
      "    fold  0:  [0.97178916]\n",
      "    fold  1:  [0.97413055]\n",
      "    fold  2:  [0.97355948]\n",
      "    fold  3:  [0.97413055]\n",
      "    fold  4:  [0.97447173]\n",
      "    ----\n",
      "    MEAN:     [0.97361629] + [0.00095941]\n",
      "    FULL:     [0.97361628]\n",
      "\n",
      "model  5:     [AdaBoostClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.85928845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.85803209]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.84723888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.87145223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  4:  [0.87567105]\n",
      "    ----\n",
      "    MEAN:     [0.86233654] + [0.01016527]\n",
      "    FULL:     [0.86233639]\n",
      "\n",
      "modelo: stacking possui acuracia de 0.9880529544720698\n"
     ]
    }
   ],
   "source": [
    "# initializing all the base model objects with default parameters\n",
    "model_1 = RandomForestClassifier(random_state=42)\n",
    "model_2 = GradientBoostingClassifier(random_state=42)\n",
    "model_3 = SVC(random_state=42)\n",
    "model_4 = MLPClassifier(random_state=42)\n",
    "model_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "model_6 = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# putting all base model objects in one list\n",
    "all_models = [model_1, model_2, model_3, model_4, model_5, model_6]\n",
    "\n",
    "# computing the stack features\n",
    "s_train, s_test = stacking(all_models, X_train, y_train,  X_test, regression=False, n_folds=5, shuffle=True, verbose=2)\n",
    "\n",
    "# initializing the second-level model\n",
    "#model_stacking = LogisticRegression()\n",
    "model_stacking = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# fitting the second level model with stack features\n",
    "model_stacking = model_stacking.fit(s_train, y_train)\n",
    "\n",
    "# predicting the final output using stacking\n",
    "ypred_stacking = model_stacking.predict(s_test)\n",
    "\n",
    "\n",
    "list_pred = [ypred_stacking]\n",
    "modelo = ['stacking']\n",
    "metricas(list_pred, modelo)\n",
    "get_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/envs/TCC/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação - Validação (Stacking)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      9106\n",
      "         1.0       0.96      0.66      0.78       267\n",
      "         2.0       0.97      0.92      0.94       694\n",
      "         3.0       0.83      0.60      0.69        84\n",
      "         4.0       0.99      0.97      0.98       795\n",
      "\n",
      "    accuracy                           0.98     10946\n",
      "   macro avg       0.95      0.83      0.88     10946\n",
      "weighted avg       0.98      0.98      0.98     10946\n",
      "\n",
      "Relatório de Classificação - Teste (Stacking)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      9012\n",
      "         1.0       0.96      0.64      0.77       289\n",
      "         2.0       0.98      0.91      0.94       754\n",
      "         3.0       0.88      0.72      0.79        78\n",
      "         4.0       0.99      0.97      0.98       813\n",
      "\n",
      "    accuracy                           0.98     10946\n",
      "   macro avg       0.96      0.85      0.89     10946\n",
      "weighted avg       0.98      0.98      0.98     10946\n",
      "\n",
      "Especificidade Média do Stacking (Teste): 0.9790\n",
      "Especificidade Média do Stacking (Validação): 0.9791\n"
     ]
    }
   ],
   "source": [
    "for model in all_models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "s_val = np.column_stack([model.predict(X_val) for model in all_models])\n",
    "\n",
    "y_val_pred = model_stacking.predict(s_val)\n",
    "classification_report_val = classification_report(y_val, y_val_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "y_test_pred = model_stacking.predict(s_test)\n",
    "classification_report_test = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "print(\"Relatório de Classificação - Validação (Stacking)\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n",
    "\n",
    "print(\"Relatório de Classificação - Teste (Stacking)\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "specificities_test = []\n",
    "for i in range(len(cm_test)):\n",
    "    TN = np.sum(cm_test) - np.sum(cm_test[i, :]) - np.sum(cm_test[:, i]) + cm_test[i, i]\n",
    "    FP = np.sum(cm_test[:, i]) - cm_test[i, i]\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    specificities_test.append(specificity)\n",
    "\n",
    "specificity_mean_test = np.mean(specificities_test)\n",
    "print(f\"Especificidade Média do Stacking (Teste): {specificity_mean_test:.4f}\")\n",
    "\n",
    "specificities_val = []\n",
    "for i in range(len(cm_val)):\n",
    "    TN = np.sum(cm_val) - np.sum(cm_val[i, :]) - np.sum(cm_val[:, i]) + cm_val[i, i]\n",
    "    FP = np.sum(cm_val[:, i]) - cm_val[i, i]\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    specificities_val.append(specificity)\n",
    "\n",
    "specificity_mean_val = np.mean(specificities_val)\n",
    "print(f\"Especificidade Média do Stacking (Validação): {specificity_mean_val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
